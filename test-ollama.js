#!/usr/bin/env node

// Script de test pour v√©rifier l'int√©gration Ollama
import { queryOllama } from './server/ai/ollama.js';

async function testOllamaIntegration() {
  console.log('üß™ Test de l\'int√©gration Ollama...\n');
  
  // Test 1: V√©rifier la connexion √† Ollama
  console.log('1Ô∏è‚É£ Test de connexion √† Ollama...');
  try {
    const response = await queryOllama("Bonjour, peux-tu me dire 'Test r√©ussi' en fran√ßais ?");
    console.log('‚úÖ R√©ponse Ollama:', response);
    
    if (response.includes('‚ö†Ô∏è')) {
      console.log('‚ùå Ollama n\'est pas disponible. Veuillez d√©marrer le service avec: ollama serve');
      console.log('üí° Assurez-vous que le mod√®le llama3.2:1b est install√© avec: ollama pull llama3.2:1b');
      process.exit(1);
    } else {
      console.log('‚úÖ Ollama fonctionne correctement !');
    }
  } catch (error) {
    console.log('‚ùå Erreur lors du test Ollama:', error);
    process.exit(1);
  }
  
  // Test 2: Test avec un prompt de coaching
  console.log('\n2Ô∏è‚É£ Test avec un prompt de coaching...');
  try {
    const coachingResponse = await queryOllama("Donne-moi un conseil court pour am√©liorer ma forme physique");
    console.log('‚úÖ R√©ponse coaching:', coachingResponse);
  } catch (error) {
    console.log('‚ùå Erreur lors du test coaching:', error);
  }
  
  console.log('\nüéâ Tests termin√©s ! Synrgy est pr√™t √† utiliser Ollama.');
}

// Ex√©cuter les tests
testOllamaIntegration().catch(console.error);
